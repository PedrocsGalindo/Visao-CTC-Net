{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install synapseclient"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_i8m2jA1j3gX",
        "outputId": "e61de5b2-0bfe-4001-eb6c-bf284db79722"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: synapseclient in /usr/local/lib/python3.12/dist-packages (4.10.0)\n",
            "Requirement already satisfied: requests<3.0,>=2.22.0 in /usr/local/lib/python3.12/dist-packages (from synapseclient) (2.32.4)\n",
            "Requirement already satisfied: urllib3<2,>=1.26.18 in /usr/local/lib/python3.12/dist-packages (from synapseclient) (1.26.20)\n",
            "Requirement already satisfied: deprecated<2.0,>=1.2.4 in /usr/local/lib/python3.12/dist-packages (from synapseclient) (1.2.18)\n",
            "Requirement already satisfied: opentelemetry-api>=1.21.0 in /usr/local/lib/python3.12/dist-packages (from synapseclient) (1.37.0)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.21.0 in /usr/local/lib/python3.12/dist-packages (from synapseclient) (1.37.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-http>=1.21.0 in /usr/local/lib/python3.12/dist-packages (from synapseclient) (1.37.0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-httpx>=0.48b0 in /usr/local/lib/python3.12/dist-packages (from synapseclient) (0.58b0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-requests>=0.48b0 in /usr/local/lib/python3.12/dist-packages (from synapseclient) (0.58b0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-threading>=0.48b0 in /usr/local/lib/python3.12/dist-packages (from synapseclient) (0.58b0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-urllib>=0.48b0 in /usr/local/lib/python3.12/dist-packages (from synapseclient) (0.58b0)\n",
            "Requirement already satisfied: nest-asyncio~=1.6.0 in /usr/local/lib/python3.12/dist-packages (from synapseclient) (1.6.0)\n",
            "Requirement already satisfied: asyncio-atexit~=1.0.1 in /usr/local/lib/python3.12/dist-packages (from synapseclient) (1.0.1)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.12/dist-packages (from synapseclient) (0.28.1)\n",
            "Requirement already satisfied: httpcore>=1.0.9 in /usr/local/lib/python3.12/dist-packages (from synapseclient) (1.0.9)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.66.2 in /usr/local/lib/python3.12/dist-packages (from synapseclient) (4.67.1)\n",
            "Requirement already satisfied: async-lru~=2.0.4 in /usr/local/lib/python3.12/dist-packages (from synapseclient) (2.0.5)\n",
            "Requirement already satisfied: psutil~=5.9.8 in /usr/local/lib/python3.12/dist-packages (from synapseclient) (5.9.8)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.12/dist-packages (from deprecated<2.0,>=1.2.4->synapseclient) (1.17.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpcore>=1.0.9->synapseclient) (2025.10.5)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore>=1.0.9->synapseclient) (0.16.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->synapseclient) (4.11.0)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->synapseclient) (3.11)\n",
            "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-api>=1.21.0->synapseclient) (8.7.0)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-api>=1.21.0->synapseclient) (4.15.0)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-http>=1.21.0->synapseclient) (1.70.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.37.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-http>=1.21.0->synapseclient) (1.37.0)\n",
            "Requirement already satisfied: opentelemetry-proto==1.37.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-http>=1.21.0->synapseclient) (1.37.0)\n",
            "Requirement already satisfied: protobuf<7.0,>=5.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-proto==1.37.0->opentelemetry-exporter-otlp-proto-http>=1.21.0->synapseclient) (5.29.5)\n",
            "Requirement already satisfied: opentelemetry-instrumentation==0.58b0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-instrumentation-httpx>=0.48b0->synapseclient) (0.58b0)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.58b0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-instrumentation-httpx>=0.48b0->synapseclient) (0.58b0)\n",
            "Requirement already satisfied: opentelemetry-util-http==0.58b0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-instrumentation-httpx>=0.48b0->synapseclient) (0.58b0)\n",
            "Requirement already satisfied: packaging>=18.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-instrumentation==0.58b0->opentelemetry-instrumentation-httpx>=0.48b0->synapseclient) (25.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0,>=2.22.0->synapseclient) (3.4.4)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.21.0->synapseclient) (3.23.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx>=0.27.0->synapseclient) (1.3.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, shutil\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "d4V0YR2YCHK-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7kQvXkZO_tNE"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "\n",
        "SYS_TOKEN = userdata.get('SYS_TOKEN')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import synapseclient\n",
        "import synapseutils\n",
        "\n",
        "import imageio.v2 as imageio\n",
        "from pathlib import Path\n",
        "import nibabel as nib\n",
        "\n",
        "parent_id = \"syn3193805\"  # projeto raiz\n",
        "pastas_desejadas = {\n",
        "    \"averaged-testing-images\",\n",
        "    \"averaged-training-images\",\n",
        "    \"averaged-training-labels\",\n",
        "}"
      ],
      "metadata": {
        "id": "G154Y27HCC2D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load Data if need"
      ],
      "metadata": {
        "id": "sQPa6aXBKk2-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Utils\n",
        "\n",
        "def to_uint8(img2d, p_low=1, p_high=99):\n",
        "    \"\"\"Normaliza para uint8 usando percentis (evita dividir por zero e melhora contraste).\"\"\"\n",
        "    x = np.asarray(img2d, dtype=np.float32)\n",
        "    # Lida com constantes / NaN\n",
        "    if not np.isfinite(x).any():\n",
        "        return np.zeros_like(x, dtype=np.uint8)\n",
        "    lo, hi = np.percentile(x[np.isfinite(x)], [p_low, p_high])\n",
        "    if hi <= lo:\n",
        "        lo, hi = np.nanmin(x), np.nanmax(x)\n",
        "        if not np.isfinite(lo) or not np.isfinite(hi) or hi <= lo:\n",
        "            return np.zeros_like(x, dtype=np.uint8)\n",
        "    x = np.clip((x - lo) / (hi - lo), 0, 1)\n",
        "    return (x * 255).astype(np.uint8)\n",
        "\n",
        "def _move_channel_last(arr):\n",
        "    \"\"\"\n",
        "    Se existir um eixo com tamanho 3 (RGB) que não é o último, move-o para o fim.\n",
        "    Não mexe se já estiver adequado.\n",
        "    \"\"\"\n",
        "    if arr.ndim >= 3:\n",
        "        for ax in range(arr.ndim - 1):\n",
        "            if arr.shape[ax] == 3:\n",
        "                axes = [i for i in range(arr.ndim) if i != ax] + [ax]\n",
        "                return np.transpose(arr, axes)\n",
        "    return arr\n",
        "\n",
        "def nii_to_jpgs(input_path, output_dir, rgb=False, ext=\"jpg\"):\n",
        "    input_path = Path(input_path)\n",
        "    output_dir = Path(output_dir)\n",
        "    output_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    data = nib.load(str(input_path)).get_fdata()\n",
        "    data = np.squeeze(np.asarray(data))\n",
        "    data = _move_channel_last(data)  # tenta garantir canal por último\n",
        "\n",
        "    # Casos:\n",
        "    # 2D: (H, W)\n",
        "    # 3D: (H, W, D) -> D slices, 1 canal\n",
        "    # 4D: (H, W, D, C) ou (H, W, C, D) -> tentamos canal por último\n",
        "    if data.ndim == 2:\n",
        "        # um único slice, canal único\n",
        "        ch_dir = output_dir / \"channel_0\"\n",
        "        ch_dir.mkdir(parents=True, exist_ok=True)\n",
        "        img8 = to_uint8(data)\n",
        "        imageio.imwrite(str(ch_dir / f\"channel_0_slice_0.{ext}\"), img8)\n",
        "        return\n",
        "\n",
        "    if data.ndim == 3:\n",
        "        H, W, D = data.shape\n",
        "        ch_dir = output_dir / \"channel_0\"\n",
        "        ch_dir.mkdir(parents=True, exist_ok=True)\n",
        "        for z in range(D):\n",
        "            slice2d = data[..., z]\n",
        "            img8 = to_uint8(slice2d)\n",
        "            if rgb:\n",
        "                img8 = np.stack([img8, img8, img8], axis=-1)  # H x W x 3\n",
        "            imageio.imwrite(str(ch_dir / f\"channel_0_slice_{z}.{ext}\"), img8)\n",
        "        return\n",
        "\n",
        "    if data.ndim == 4:\n",
        "        H, W, A, B = data.shape  # tentaremos D=A, C=B\n",
        "        D, C = A, B\n",
        "\n",
        "        # Se acharmos que o canal está na penúltima dimensão (ex.: (H, W, 3, D)), invertemos:\n",
        "        if C > 4 and D <= 4:\n",
        "            # provavelmente (H, W, C, D) com C pequeno; traz C para o fim\n",
        "            data = np.moveaxis(data, -2, -1)  # agora (H, W, D, C)\n",
        "            H, W, D, C = data.shape\n",
        "\n",
        "        # Agora assumimos (H, W, D, C)\n",
        "        for c in range(C):\n",
        "            ch_dir = output_dir / f\"channel_{c}\"\n",
        "            ch_dir.mkdir(parents=True, exist_ok=True)\n",
        "            for z in range(D):\n",
        "                slice2d = np.squeeze(data[..., z, c])\n",
        "                if slice2d.ndim != 2:\n",
        "                    # segurança extra\n",
        "                    print(f\"[WARN] slice {z} canal {c} shape {slice2d.shape} não é 2D; pulando.\")\n",
        "                    continue\n",
        "                img8 = to_uint8(slice2d)\n",
        "                if rgb and C == 3:\n",
        "                    # Se tivermos exatamente 3 canais e rgb=True, você pode preferir salvar 1 imagem RGB por slice\n",
        "                    # Mas mantendo sua lógica de \"por canal\", só empilhamos se pediu rgb explicitamente\n",
        "                    img8 = np.stack([img8, img8, img8], axis=-1)\n",
        "                imageio.imwrite(str(ch_dir / f\"channel_{c}_slice_{z}.{ext}\"), img8)\n",
        "        return\n",
        "\n",
        "    raise ValueError(f\"Dimensão NIfTI não suportada: shape={data.shape}\")"
      ],
      "metadata": {
        "id": "Tg8cbgUAP-iz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tempfile\n",
        "\n",
        "def decompress_gz(file_path):\n",
        "  import gzip\n",
        "\n",
        "  out_path = os.path.splitext(file_path)[0]\n",
        "\n",
        "  with gzip.open(file_path, 'rb') as f_in:\n",
        "    with open(out_path, 'wb') as f_out:\n",
        "      shutil.copyfileobj(f_in, f_out)\n",
        "\n",
        "  os.remove(file_path)\n",
        "  return out_path\n",
        "\n",
        "\n",
        "def norm(s: str) -> str:\n",
        "    return s.strip().lower().replace('_', '-')\n",
        "\n",
        "def is_labels_dir(path: str) -> bool:\n",
        "    # reconhece averaged-training-labels em qualquer parte do caminho\n",
        "    return \"averaged-training-labels\" in [norm(p) for p in Path(path).parts]\n",
        "\n",
        "def load_from_synapse():\n",
        "  with tempfile.TemporaryDirectory() as tmpdir:\n",
        "    syn = synapseclient.Synapse()\n",
        "    syn.login(authToken=SYS_TOKEN)\n",
        "\n",
        "    # 1) Baixa tudo das pastas desejadas\n",
        "    for ch in syn.getChildren(parent_id):\n",
        "        if ch[\"type\"] == \"org.sagebionetworks.repo.model.Folder\" and ch[\"name\"] in pastas_desejadas:\n",
        "            file_path = os.path.join(tmpdir, ch[\"name\"])\n",
        "            os.makedirs(file_path, exist_ok=True)\n",
        "            synapseutils.syncFromSynapse(\n",
        "                syn, ch[\"id\"], path=file_path,\n",
        "                ifcollision=\"overwrite.local\", followLink=True\n",
        "            )\n",
        "\n",
        "\n",
        "    print(\"Estrutura baixada:\")\n",
        "    for r, d, f in os.walk(tmpdir):\n",
        "        print(\"   \", os.path.relpath(r, tmpdir))\n",
        "\n",
        "    # 3) Processa NIfTIs\n",
        "    total_encontrados = total_processados = total_escritos = 0\n",
        "\n",
        "    for root, dirs, files in os.walk(tmpdir):\n",
        "      for file in files:\n",
        "        if not file.lower().endswith((\".nii\", \".nii.gz\")):\n",
        "            continue\n",
        "\n",
        "        total_encontrados += 1\n",
        "        try:\n",
        "            input_path = Path(root) / file\n",
        "            relative_path = os.path.relpath(root, tmpdir)\n",
        "\n",
        "            # Diretório de saída (preserva estrutura relativa)\n",
        "            out_dir = Path(\"/content/synapse_data/jpgs_PNGs\") / relative_path / file.replace(\".nii.gz\",\"\").replace(\".nii\",\"\")\n",
        "\n",
        "            # Descompacta se necessário (garante str e Path depois)\n",
        "            if file.lower().endswith(\".nii.gz\"):\n",
        "                print(f\"[INFO] Decompressing: {input_path}\")\n",
        "                input_path = Path(decompress_gz(str(input_path)))\n",
        "\n",
        "            # Decide formato (PNG para labels, JPG para demais)\n",
        "            salvar_png = is_labels_dir(root)\n",
        "            ext = \"png\" if salvar_png else \"jpg\"\n",
        "            print(f\"[INFO] Converting -> {ext.upper()}: {os.path.join(relative_path, file)}  out_dir={out_dir}\")\n",
        "\n",
        "            # Converte\n",
        "            antes = len(list(out_dir.glob(f\"**/*.{ext}\"))) if out_dir.exists() else 0\n",
        "            nii_to_jpgs(input_path, out_dir, rgb=False, ext=ext)\n",
        "            depois = len(list(out_dir.glob(f\"**/*.{ext}\")))\n",
        "            escritos = max(0, depois - antes)\n",
        "            total_escritos += escritos\n",
        "            total_processados += 1\n",
        "            print(f\"[OK] Escrevidos {escritos} arquivo(s) em {out_dir}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"[ERR] Falha em {os.path.join(relative_path, file)}: {type(e).__name__}: {e}\")\n",
        "\n",
        "    print(f\"[RESUMO] encontrados={total_encontrados} processados={total_processados} escritos={total_escritos}\")\n",
        "\n",
        "def apagar():\n",
        "  import shutil\n",
        "\n",
        "  shutil.rmtree(\"/content/synapse_data\")\n",
        "\n",
        "# Load if need\n",
        "if not Path(\"/content/synapse_data\").exists():\n",
        "  load_from_synapse()"
      ],
      "metadata": {
        "id": "a2syyZj9KkZw",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset loader"
      ],
      "metadata": {
        "id": "BtGpHcUVVRmq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision.io import read_image\n",
        "from torchvision.transforms.functional import resize\n",
        "\n",
        "class SynapseDataset(Dataset):\n",
        "  # Precisa ser (3, 224, 224)\n",
        "  # Resnet espera 3 canais\n",
        "  # swim espera 224,224\n",
        "  def __init__(self, img_dirs, labels_dirs, size=(224, 224)):\n",
        "      self.items = []\n",
        "      self.size = size\n",
        "\n",
        "      # path to imgs\n",
        "      for img_dir, lbs_dir in zip(img_dirs, labels_dirs):\n",
        "        for im, lb in zip(sorted(Path(img_dir).iterdir()),sorted(Path(lbs_dir).iterdir())):\n",
        "            img = read_image(str(im)).float() / 255.0\n",
        "            lab = read_image(str(lb)).float() / 255.0\n",
        "            self.items.append((img, lab))\n",
        "\n",
        "  def __len__(self):\n",
        "      return len(self.items)\n",
        "\n",
        "  def _norm(self, img, c3 = True):\n",
        "    img = resize(img, self.size, antialias=True)\n",
        "    if img.ndim == 2:\n",
        "        img = img.unsqueeze(0)              # [H,W] → [1,H,W]\n",
        "    if img.shape[0] == 1 and c3:\n",
        "        img = img.repeat(3, 1, 1)           # força 3 canais\n",
        "    return img\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "      img = self._norm(self.items[idx][0])\n",
        "      label = self._norm(self.items[idx][1], c3 = False) # Melhor n ter 3 canais\n",
        "      # 0 ou 1\n",
        "      label = label.to(torch.float32)\n",
        "      label = (label > 0).to(torch.float32)\n",
        "      return img, label\n",
        "\n",
        "training_data = Path(\"/content/synapse_data/jpgs_PNGs/averaged-training-images\")\n",
        "training_labels = Path(\"/content/synapse_data/jpgs_PNGs/averaged-training-labels\")\n",
        "\n",
        "def load_data_and_labels_paths():\n",
        "  # Return: List[data_path], List[labels_path]\n",
        "\n",
        "  data = []\n",
        "  labels =[]\n",
        "  for dir in os.listdir(training_data):\n",
        "    img_dir = training_data / dir / \"channel_0\"\n",
        "    label_dir = training_labels / f\"{dir}_seg\" / \"channel_0\"\n",
        "    data.append(img_dir)\n",
        "    labels.append(label_dir)\n",
        "\n",
        "  return data, labels\n",
        "\n",
        "\"\"\"\n",
        "Exemplo:\n",
        "data, labels = load_data_and_labels_paths()\n",
        "dataset = SynapseDataset(data, labels)\n",
        "\"\"\"\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "OHDhd3GyFY4j",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c20e7d17-7019-4096-cdb7-fb5cb2202b5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nExemplo:\\ndata, labels = load_data_and_labels_paths()\\ndataset = SynapseDataset(data, labels)\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "MODELOS"
      ],
      "metadata": {
        "id": "g8mpkabUMPQy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import cv2\n",
        "from glob import glob\n",
        "from typing import List, Tuple\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import timm\n",
        "\n",
        "\n",
        "# Config\n",
        "BATCH       = 8\n",
        "EPOCHS      = 50\n",
        "LR          = 1e-3   # simples: Adam\n",
        "ALPHA       = 0.6    # (1-α)*CE + α*Dice\n",
        "\n",
        "\n",
        "class ConvBNReLU(nn.Module):\n",
        "    def __init__(self, c_in, c_out, k=3, s=1, p=1):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Conv2d(c_in, c_out, k, s, p, bias=False),\n",
        "            nn.BatchNorm2d(c_out),\n",
        "            nn.ReLU(inplace=True),\n",
        "        )\n",
        "    def forward(self, x): return self.net(x)\n",
        "\n",
        "class DoubleConv(nn.Module):\n",
        "    def __init__(self, c_in, c_out):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            ConvBNReLU(c_in, c_out),\n",
        "            ConvBNReLU(c_out, c_out),\n",
        "        )\n",
        "    def forward(self, x): return self.net(x)\n",
        "\n",
        "\n",
        "# FCM (ResNet + Swin)\n",
        "\n",
        "class SE(nn.Module):\n",
        "    # atenção por canal\n",
        "    def __init__(self, c, r=16):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Conv2d(c, c//r, 1)\n",
        "        self.fc2 = nn.Conv2d(c//r, c, 1)\n",
        "    def forward(self, x):\n",
        "        w = F.adaptive_avg_pool2d(x, 1)\n",
        "        w = F.relu(self.fc1(w), inplace=True)\n",
        "        w = torch.sigmoid(self.fc2(w))\n",
        "        return x * w\n",
        "\n",
        "class FCM(nn.Module):\n",
        "    \"\"\"\n",
        "    f: feature da ResNet (B,C,H,W)\n",
        "    g: feature da Swin   (B,C,H,W)\n",
        "    saída: (B,C,H,W)\n",
        "    \"\"\"\n",
        "    def __init__(self, C):\n",
        "        super().__init__()\n",
        "        self.cab = SE(C)\n",
        "        self.mix = ConvBNReLU(3*C, C, k=1, s=1, p=0)  # concat -> 1x1\n",
        "\n",
        "    def forward(self, f, g):\n",
        "        # Cross-domain Conditioning (CNN X Swin)\n",
        "        gf = g + F.adaptive_avg_pool2d(f, 1)  # g guiado por f\n",
        "        fg = f + F.adaptive_avg_pool2d(g, 1)  # f guiado por g\n",
        "\n",
        "        # correlação ponto-a-ponto\n",
        "        corr = f * g\n",
        "        # atenção por canal em g condicionado\n",
        "        g_att = self.cab(gf)\n",
        "\n",
        "        x = torch.cat([fg, corr, g_att], dim=1)\n",
        "        return self.mix(x)\n",
        "\n",
        "def nhwc_to_nchw(feat):\n",
        "    if feat.ndim == 4:\n",
        "        feat = feat.permute(0, 3, 1, 2).contiguous()\n",
        "    return feat\n",
        "\n",
        "class DualEncoder(nn.Module):\n",
        "    def __init__(self, c_embed=48):\n",
        "        super().__init__()\n",
        "\n",
        "        # out_indices -> Quais estagios das features\n",
        "        # out_indices -> 3 para o \"gargalo\"\n",
        "        # 3 escalas compatíveis\n",
        "        self.cnn  = timm.create_model('resnet34', pretrained=True, features_only=True, out_indices=(1,2,3))\n",
        "        self.swin = timm.create_model('swin_small_patch4_window7_224', pretrained=True, features_only=True, out_indices=(0,1,2,3))\n",
        "\n",
        "        c_cnn  = self.cnn.feature_info.channels()          #  [128, 256, 512]\n",
        "        c_swin = self.swin.feature_info.channels()         #  [96, 192, 384, 768]\n",
        "\n",
        "        # Ajuste do numero de canais\n",
        "        self.proj_c = nn.ModuleList([nn.Conv2d(c, c_embed*(2**i), 1) for i,c in enumerate(c_cnn)])\n",
        "        self.proj_s = nn.ModuleList([nn.Conv2d(c, c_embed*(2**i), 1) for i,c in enumerate(c_swin[:3])])\n",
        "        self.c4_out = c_swin[3]  # 768\n",
        "\n",
        "    def forward(self, x):\n",
        "        f1,f2,f3 = self.cnn(x)            # H/4, H/8, H/16 (aprox)\n",
        "        g1,g2,g3,g4 = self.swin(x)        # H/4, H/8, H/16, H/32\n",
        "        # projetar canais\n",
        "        f1,f2,f3 = [p(t) for p,t in zip(self.proj_c, (f1,f2,f3))]\n",
        "        g1,g2,g3 = [p(nhwc_to_nchw(t)) for p,t in zip(self.proj_s, (g1,g2,g3))] #swin retorna nhwc\n",
        "        g4 = nhwc_to_nchw(g4)\n",
        "        return (f1,f2,f3), (g1,g2,g3,g4), self.c4_out\n",
        "\n",
        "# Decoder\n",
        "class Up(nn.Module):\n",
        "    def __init__(self, c_in, c_skip, c_out):\n",
        "        super().__init__()\n",
        "        self.up   = nn.ConvTranspose2d(c_in, c_out, 2, 2)\n",
        "        self.conv = DoubleConv(c_out + c_skip, c_out)\n",
        "    def forward(self, x, skip):\n",
        "        x = self.up(x)\n",
        "        if x.shape[-2:] != skip.shape[-2:]:\n",
        "            x = F.interpolate(x, size=skip.shape[-2:], mode='bilinear', align_corners=False)\n",
        "        x = torch.cat([x, skip], dim=1)\n",
        "        return self.conv(x)\n",
        "\n",
        "class CTC(nn.Module):\n",
        "    \"\"\"\n",
        "    ResNet34 + Swin (fusão em 3 níveis) + decoder leve\n",
        "    \"\"\"\n",
        "    def __init__(self, c_embed=48):\n",
        "        super().__init__()\n",
        "        self.d_enc = DualEncoder(c_embed=c_embed)\n",
        "\n",
        "        # FCMs em três escalas\n",
        "        self.fcm1 = FCM(c_embed*1)  # H/4\n",
        "        self.fcm2 = FCM(c_embed*2)  # H/8\n",
        "        self.fcm3 = FCM(c_embed*4)  # H/16\n",
        "\n",
        "        # Gargalo: reduzir g4 (768) -> 8C\n",
        "        dummy_enc = timm.create_model('swin_small_patch4_window7_224', pretrained=False, features_only=True, out_indices=(0,1,2,3))\n",
        "        swin_c4 = dummy_enc.feature_info.channels()[-1]  # 768\n",
        "        self.reduce4 = nn.Conv2d(swin_c4, c_embed*8, 1)\n",
        "\n",
        "        # Decoder, usando m3,m2,m1 como skips\n",
        "        self.up3 = Up(c_embed*8, c_embed*4, c_embed*4)   # H/16 -> H/8\n",
        "        self.up2 = Up(c_embed*4, c_embed*2, c_embed*2)   # H/8  -> H/4\n",
        "        self.up1 = Up(c_embed*2, c_embed*1, c_embed*1)   # H/4  -> H/2 (depois interpolamos p/ H)\n",
        "\n",
        "        self.head = nn.Conv2d(c_embed*1, 1, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "      (f1,f2,f3), (g1,g2,g3,g4), _ = self.d_enc(x)\n",
        "\n",
        "      # Alinha resoluções, caso necessário\n",
        "      if f1.shape[-2:] != g1.shape[-2:]:\n",
        "          g1 = F.interpolate(g1, size=f1.shape[-2:], mode='bilinear', align_corners=False)\n",
        "      if f2.shape[-2:] != g2.shape[-2:]:\n",
        "          g2 = F.interpolate(g2, size=f2.shape[-2:], mode='bilinear', align_corners=False)\n",
        "      if f3.shape[-2:] != g3.shape[-2:]:\n",
        "          g3 = F.interpolate(g3, size=f3.shape[-2:], mode='bilinear', align_corners=False)\n",
        "\n",
        "\n",
        "      # Fusão complementar\n",
        "      m1 = self.fcm1(f1, g1)\n",
        "      m2 = self.fcm2(f2, g2)\n",
        "      m3 = self.fcm3(f3, g3)\n",
        "\n",
        "      # Gargalo\n",
        "      x  = self.reduce4(g4)\n",
        "\n",
        "      # Decodificação\n",
        "      x  = self.up3(x, m3)\n",
        "      x  = self.up2(x, m2)\n",
        "      x  = self.up1(x, m1)\n",
        "\n",
        "      # trazer de H/2 para 2H\n",
        "      x  = F.interpolate(x, scale_factor=4, mode='bilinear', align_corners=False)\n",
        "\n",
        "      return self.head(x)\n",
        "\n",
        "# =========================\n",
        "# Loss & Métrica\n",
        "# =========================\n",
        "def dice_coef_binary(logits, target, eps=1e-6):\n",
        "    # logits: Bx1xHxW, target: BxHxW (0/1)\n",
        "    prob = torch.sigmoid(logits)\n",
        "    pred = (prob > 0.5).float()\n",
        "    t = target.float()\n",
        "    inter = (pred * t).sum()\n",
        "    denom = pred.sum() + t.sum()\n",
        "    return (2*inter + eps) / (denom + eps)\n",
        "\n",
        "def remove_3_chanel(x):\n",
        "  if x.ndim == 4:\n",
        "\n",
        "    if x.shape[1] == 3:\n",
        "        # máscara veio RGB -> colapsa para binária\n",
        "        # regra: qualquer canal >0 vira 1\n",
        "        x = (x > 0).any(dim=1, keepdim=True).float()  # [B,1,H,W]\n",
        "\n",
        "def mixed_loss_binary(logits, target, alpha=0.6):\n",
        "  bce  = F.binary_cross_entropy_with_logits(logits, target)\n",
        "  dice = 1 - dice_coef_binary(logits, target)\n",
        "  return (1 - alpha) * bce + alpha * dice"
      ],
      "metadata": {
        "id": "POVheBQXMO1d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def splitData(data, labels):\n",
        "  size = len(labels)\n",
        "  idx = np.random.permutation(size)\n",
        "  data  = [data[i] for i in idx]\n",
        "  labels = [labels[i] for i in idx]\n",
        "\n",
        "\n",
        "  split = int(size * 0.8)\n",
        "\n",
        "  train = data[:split], labels[:split]    # 80%\n",
        "  val   = data[split:], labels[split:]    # 20%\n",
        "\n",
        "  return train, val\n",
        "\n",
        "# Onde vai rodar\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "\n",
        "data, labels = load_data_and_labels_paths()\n",
        "\n",
        "train, val = splitData(data, labels)\n",
        "train_ds = SynapseDataset(train[0], train[1])\n",
        "val_ds = SynapseDataset(val[0], val[1])\n",
        "\n",
        "train_dl = DataLoader(train_ds, batch_size=BATCH, shuffle=True,  num_workers=4, pin_memory=True)\n",
        "val_dl   = DataLoader(val_ds,   batch_size=BATCH, shuffle=False, num_workers=4, pin_memory=True)\n",
        "\n",
        "model = CTC(c_embed=48).to(DEVICE)\n",
        "opt   = torch.optim.Adam(model.parameters(), lr=LR)\n",
        "\n",
        "best = 0.0\n",
        "for epoch in range(1, EPOCHS+1):\n",
        "    # ---- treino\n",
        "    model.train()\n",
        "    losses=[]\n",
        "    # conjunto de imagens e máscaras\n",
        "    for img,mask in train_dl:\n",
        "        img,mask = img.to(DEVICE), mask.to(DEVICE)\n",
        "        opt.zero_grad()\n",
        "        logits = model(img)\n",
        "        loss = mixed_loss_binary(logits, mask)\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        losses.append(loss.item())\n",
        "    tr_loss = float(np.mean(losses)) if losses else 0.0\n",
        "\n",
        "    # ---- validação\n",
        "    model.eval()\n",
        "    dices=[]\n",
        "    with torch.no_grad():\n",
        "        for img,mask in val_dl:\n",
        "            img,mask = img.to(DEVICE), mask.to(DEVICE)\n",
        "            logits = model(img)\n",
        "            dices.append(dice_coef_binary(logits,mask).item())\n",
        "    val_dice = float(np.mean(dices)) if dices else 0.0\n",
        "\n",
        "    print(f\"[{epoch:03d}] train_loss={tr_loss:.4f}  val_dice={val_dice:.4f}\")\n",
        "\n",
        "    if val_dice > best:\n",
        "        best = val_dice\n",
        "        torch.save(model.state_dict(), \"ctc_tiny_best.pth\")\n",
        "        print(f\"  ↑ salvo: ctc_tiny_best.pth (Dice {best:.4f})\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "86iLUxHbRYGJ",
        "outputId": "28212828-5850-4ecb-8449-af1b8e40fb54"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:py.warnings:/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "\n",
            "WARNING:py.warnings:/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "\n",
            "WARNING:py.warnings:/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([7, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([2, 48, 56, 56])\n",
            "[001] train_loss=0.6962  val_dice=0.0000\n",
            "  ↑ salvo: ctc_tiny_best.pth (Dice 0.0000)\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([7, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([2, 48, 56, 56])\n",
            "[002] train_loss=0.6322  val_dice=0.0032\n",
            "  ↑ salvo: ctc_tiny_best.pth (Dice 0.0032)\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([7, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([2, 48, 56, 56])\n",
            "[003] train_loss=0.1873  val_dice=0.7158\n",
            "  ↑ salvo: ctc_tiny_best.pth (Dice 0.7158)\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([7, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([2, 48, 56, 56])\n",
            "[004] train_loss=0.1112  val_dice=0.8051\n",
            "  ↑ salvo: ctc_tiny_best.pth (Dice 0.8051)\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([7, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([2, 48, 56, 56])\n",
            "[005] train_loss=0.0946  val_dice=0.8134\n",
            "  ↑ salvo: ctc_tiny_best.pth (Dice 0.8134)\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([7, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([2, 48, 56, 56])\n",
            "[006] train_loss=0.0838  val_dice=0.8204\n",
            "  ↑ salvo: ctc_tiny_best.pth (Dice 0.8204)\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n",
            "torch.Size([8, 48, 56, 56])\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2924851382.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmixed_loss_binary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-3960057647.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m       \u001b[0;34m(\u001b[0m\u001b[0mf1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mf2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mf3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mg1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mg2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mg3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mg4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0md_enc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m       \u001b[0;31m# Alinha resoluções, caso necessário\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-3960057647.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0mf1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mf2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mf3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m            \u001b[0;31m# H/4, H/8, H/16 (aprox)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0mg1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mg2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mg3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mg4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mswin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m        \u001b[0;31m# H/4, H/8, H/16, H/32\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m         \u001b[0;31m# projetar canais\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0mf1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mf2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mf3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproj_c\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mf1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mf2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mf3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/timm/models/_features.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_collect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/timm/models/_features.py\u001b[0m in \u001b[0;36m_collect\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    297\u001b[0m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mfirst_or_last_module\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mcheckpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 299\u001b[0;31m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_layers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/timm/models/swin_transformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    601\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheckpoint_seq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 603\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    604\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    242\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/timm/models/swin_transformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    430\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop_path1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_attn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 432\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop_path2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    433\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/timm/layers/mlp.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}